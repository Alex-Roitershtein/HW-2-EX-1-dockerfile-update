{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54eb061f",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 10\n",
    "\n",
    "# Lab: Deep Learning\n",
    "In this section we  demonstrate how to fit the examples discussed\n",
    "in the text. We use the `Python`  `torch` package, along with the\n",
    "`pytorch_lightning` package which provides utilities to simplify\n",
    "fitting and evaluating models.  This code can be impressively fast\n",
    "with certain  special processors,  such as Apple’s new M1 chip. The package is well-structured, flexible, and will feel comfortable\n",
    "to `Python`  users. A good companion is the site\n",
    "[pytorch.org/tutorials](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "Much of our code is adapted from there, as well as the `pytorch_lightning` documentation. {The precise URLs at the time of writing are <https://pytorch.org/tutorials/beginner/basics/intro.html> and <https://pytorch-lightning.readthedocs.io/en/latest/>.}\n",
    "\n",
    "We start with several standard imports that we have  seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01aad02e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.linear_model import \\\n",
    "     (LinearRegression,\n",
    "      LogisticRegression,\n",
    "      Lasso)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from sklearn.model_selection import \\\n",
    "     (train_test_split,\n",
    "      GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e091b1",
   "metadata": {},
   "source": [
    "### Torch-Specific Imports\n",
    "There are a number of imports for `torch`. (These are not\n",
    "included with `ISLP`, so must be installed separately.)\n",
    "First we import the main library\n",
    "and essential tools used to specify sequentially-structured networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267afcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdedfbb",
   "metadata": {},
   "source": [
    "There are several other helper packages for `torch`. For instance,\n",
    "the `torchmetrics` package has utilities to compute\n",
    "various metrics to evaluate performance when fitting\n",
    "a model. The `torchinfo` package provides a useful\n",
    "summary of the layers of a model. We use the `read_image()`\n",
    "function when loading test images in Section 10.9.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5548bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import (MeanAbsoluteError,\n",
    "                          R2Score)\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1accea",
   "metadata": {},
   "source": [
    "The package `pytorch_lightning` is a somewhat higher-level\n",
    "interface to `torch` that simplifies the specification and\n",
    "fitting of\n",
    "models by reducing the amount of boilerplate code needed\n",
    "(compared to using `torch` alone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372edabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71a03f",
   "metadata": {},
   "source": [
    "In order to reproduce results we use `seed_everything()`. We will also instruct `torch` to use deterministic algorithms\n",
    "where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b905254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(0, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b33ad",
   "metadata": {},
   "source": [
    "We will use several datasets shipped with `torchvision` for our\n",
    "examples: a pretrained network for image classification,\n",
    "as well as some transforms used for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b146a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.datasets import MNIST, CIFAR100\n",
    "from torchvision.models import (resnet50,\n",
    "                                ResNet50_Weights)\n",
    "from torchvision.transforms import (Resize,\n",
    "                                    Normalize,\n",
    "                                    CenterCrop,\n",
    "                                    ToTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd4a91",
   "metadata": {},
   "source": [
    "We have provided a few utilities in `ISLP` specifically for this lab.\n",
    "The `SimpleDataModule` and `SimpleModule` are simple\n",
    "versions of objects used in `pytorch_lightning`, the\n",
    "high-level module for fitting `torch` models. Although more advanced\n",
    "uses such as computing on graphical processing units (GPUs) and parallel data processing\n",
    "are possible in this module, we will not be focusing much on these\n",
    "in this lab. The `ErrorTracker` handles\n",
    "collections of targets and predictions over each mini-batch\n",
    "in the validation or test stage, allowing computation\n",
    "of the metric over the entire validation or test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e669f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.torch import (SimpleDataModule,\n",
    "                        SimpleModule,\n",
    "                        ErrorTracker,\n",
    "                        rec_num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8babe9",
   "metadata": {},
   "source": [
    "In addition we have included some helper\n",
    "functions to load the\n",
    "`IMDb` database, as well as a lookup that maps integers\n",
    "to particular keys in the database. We’ve included\n",
    "a slightly modified copy of the preprocessed\n",
    "`IMDb` data from `keras`, a separate package\n",
    "for fitting deep learning models. This saves us significant\n",
    "preprocessing and allows us to focus on specifying and fitting\n",
    "the models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84439147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.torch.imdb import (load_lookup,\n",
    "                             load_tensor,\n",
    "                             load_sparse,\n",
    "                             load_sequential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3546d2",
   "metadata": {},
   "source": [
    "Finally, we introduce some utility imports  not directly related to\n",
    "`torch`.\n",
    "The `glob()` function from the `glob` module is used\n",
    "to find all files matching wildcard characters, which we will use\n",
    "in our example applying the `ResNet50` model\n",
    "to some of our own images.\n",
    "The `json` module will be used to load\n",
    "a JSON file for looking up classes to identify the labels of the\n",
    "pictures in the `ResNet50` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53732c4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2476aa9",
   "metadata": {},
   "source": [
    "## Single Layer Network on Hitters Data\n",
    "We start by fitting the models in Section 10.6 on the `Hitters` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e04cda",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "Hitters = load_data('Hitters').dropna()\n",
    "n = Hitters.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd3fd8",
   "metadata": {},
   "source": [
    " We will fit two linear models (least squares  and lasso) and  compare their performance\n",
    "to that of a neural network. For this comparison we will use mean absolute error on a validation dataset.\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\mbox{MAE}(y,\\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n |y_i-\\hat{y}_i|.\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "We set up the model matrix and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7453a041",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = MS(Hitters.columns.drop('Salary'), intercept=False)\n",
    "X = model.fit_transform(Hitters).to_numpy()\n",
    "Y = Hitters['Salary'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d8a37",
   "metadata": {},
   "source": [
    "The `to_numpy()`  method above converts `pandas`\n",
    "data frames or series to `numpy` arrays.\n",
    "We do this because we will need to  use `sklearn` to fit the lasso model,\n",
    "and it requires this conversion. \n",
    "We also use  a linear regression method from `sklearn`, rather than the method\n",
    "in Chapter~3 from `statsmodels`, to facilitate the comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625dfc4",
   "metadata": {},
   "source": [
    "We now split the data into test and training, fixing the random\n",
    "state used by `sklearn` to do the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8debfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, \n",
    " X_test,\n",
    " Y_train,\n",
    " Y_test) = train_test_split(X,\n",
    "                            Y,\n",
    "                            test_size=1/3,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfa45a",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "We fit the linear model and evaluate the test error directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a52a6652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.7152883314631"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_lm = LinearRegression().fit(X_train, Y_train)\n",
    "Yhat_test = hit_lm.predict(X_test)\n",
    "np.abs(Yhat_test - Y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263d822",
   "metadata": {},
   "source": [
    "Next we fit the lasso using `sklearn`. We are using\n",
    "mean absolute error to select and evaluate a model, rather than mean squared error.\n",
    "The specialized solver we used in Section 6.5.2 uses only mean squared error. So here, with a bit more work,  we create a cross-validation grid and perform the cross-validation directly.  \n",
    "\n",
    "We encode a pipeline with two steps: we first normalize the features using a `StandardScaler()` transform,\n",
    "and then fit the lasso without further normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4afcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "lasso = Lasso(warm_start=True, max_iter=30000)\n",
    "standard_lasso = Pipeline(steps=[('scaler', scaler),\n",
    "                                 ('lasso', lasso)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b1cc3",
   "metadata": {},
   "source": [
    "We need to create a grid of values for $\\lambda$. As is common practice, \n",
    "we choose a grid of 100 values of $\\lambda$, uniform on the log scale from `lam_max` down to  `0.01*lam_max`. Here  `lam_max` is the smallest value of\n",
    "$\\lambda$ with an  all-zero solution. This value equals the largest absolute inner-product between any predictor and the (centered) response. {The derivation of this result is beyond the scope of this book.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4073cd77",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "X_s = scaler.fit_transform(X_train)\n",
    "n = X_s.shape[0]\n",
    "lam_max = np.fabs(X_s.T.dot(Y_train - Y_train.mean())).max() / n\n",
    "param_grid = {'lasso__alpha': np.exp(np.linspace(0, np.log(0.01), 100))\n",
    "             * lam_max}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45126760",
   "metadata": {},
   "source": [
    "Note that we had to transform the data first, since the scale of the variables impacts the choice of $\\lambda$.\n",
    "We now perform cross-validation using this sequence of $\\lambda$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc45ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(10,\n",
    "           shuffle=True,\n",
    "           random_state=1)\n",
    "grid = GridSearchCV(standard_lasso,\n",
    "                    param_grid,\n",
    "                    cv=cv,\n",
    "                    scoring='neg_mean_absolute_error')\n",
    "grid.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411b3c2",
   "metadata": {},
   "source": [
    "We extract the lasso model with best cross-validated mean absolute error, and evaluate its\n",
    "performance on `X_test` and `Y_test`, which were not used in\n",
    "cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c82dee46",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.6754837478029"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_lasso = grid.best_estimator_\n",
    "Yhat_test = trained_lasso.predict(X_test)\n",
    "np.fabs(Yhat_test - Y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83daf823",
   "metadata": {},
   "source": [
    "This is similar to the results we got for the linear model fit by least squares. However, these results can vary a lot for different train/test splits; we encourage the reader to try a different seed in code block 12 and rerun the subsequent code up to this point.\n",
    "\n",
    "### Specifying a Network: Classes and Inheritance\n",
    "To fit the neural network, we first set up a model structure\n",
    "that describes the network.\n",
    "Doing so requires us to define new classes specific to the model we wish to fit.\n",
    "Typically this is done in  `pytorch` by sub-classing a generic\n",
    "representation of a network, which is the approach we take here.\n",
    "Although this example is simple, we will go through the steps in some detail, since it will serve us well\n",
    "for the more complex examples to follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5e4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HittersModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(HittersModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_size, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(50, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return torch.flatten(self.sequential(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b04b42",
   "metadata": {},
   "source": [
    "The `class` statement identifies the code chunk as a\n",
    "declaration for a class `HittersModel`\n",
    "that inherits from the  base class `nn.Module`. This base\n",
    "class is ubiquitous in `torch` and represents the\n",
    "mappings in the neural networks.\n",
    "\n",
    "Indented beneath the `class` statement are the methods of this class:\n",
    "in this case `__init__` and `forward`.  The `__init__` method is\n",
    "called when an instance of the class is created as in the cell\n",
    "below. In the methods, `self` always refers to an instance of the\n",
    "class. In the `__init__` method, we have attached two objects to\n",
    "`self` as attributes: `flatten` and `sequential`. These are used in\n",
    "the `forward` method to describe the map that this module implements.\n",
    "\n",
    "There is one additional line in the `__init__` method, which\n",
    "is a call to\n",
    "`super()`. This function allows subclasses (i.e. `HittersModel`)\n",
    "to access methods of the class they inherit from. For example,\n",
    "the class `nn.Module` has its own `__init__` method, which is different from\n",
    "the `HittersModel.__init__()` method we’ve written above.\n",
    "Using `super()` allows us to call the method of the base class. For\n",
    "`torch` models, we will always be making this `super()` call as it is necessary\n",
    "for the model to be properly interpreted by `torch`.\n",
    "\n",
    "The object `nn.Module` has more methods than simply `__init__` and `forward`. These\n",
    "methods are directly accessible to `HittersModel` instances because of this inheritance.\n",
    "One such method we will see shortly is the `eval()` method, used\n",
    "to disable dropout for when we want to evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff3d0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_model = HittersModel(X.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229d2e4",
   "metadata": {},
   "source": [
    "The object `self.sequential` is a composition of four maps. The\n",
    "first maps the 19 features of `Hitters` to 50 dimensions, introducing $50\\times 19+50$ parameters\n",
    "for the weights and *intercept*  of the map (often called the *bias*). This layer\n",
    "is then mapped to a ReLU layer followed by a 40% dropout layer, and finally a\n",
    "linear map down to 1 dimension, again with a bias. The total number of\n",
    "trainable parameters is therefore $50\\times 19+50+50+1=1051$.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83b59c",
   "metadata": {},
   "source": [
    "The package `torchinfo` provides a `summary()` function that neatly summarizes\n",
    "this information. We specify the size of the input and see the size\n",
    "of each tensor as it passes through layers of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5318bef9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "HittersModel                             [175, 19]                 [175]                     --\n",
       "├─Flatten: 1-1                           [175, 19]                 [175, 19]                 --\n",
       "├─Sequential: 1-2                        [175, 19]                 [175, 1]                  --\n",
       "│    └─Linear: 2-1                       [175, 19]                 [175, 50]                 1,000\n",
       "│    └─ReLU: 2-2                         [175, 50]                 [175, 50]                 --\n",
       "│    └─Dropout: 2-3                      [175, 50]                 [175, 50]                 --\n",
       "│    └─Linear: 2-4                       [175, 50]                 [175, 1]                  51\n",
       "===================================================================================================================\n",
       "Total params: 1,051\n",
       "Trainable params: 1,051\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.18\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.09\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(hit_model, \n",
    "        input_size=X_train.shape,\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415949bf",
   "metadata": {},
   "source": [
    "We have truncated the end of the output slightly, here and in subsequent uses.\n",
    "\n",
    "We now need to transform our training data into a form accessible to `torch`.\n",
    "The basic\n",
    "datatype in `torch` is a `tensor`, which is very similar\n",
    "to an `ndarray` from early chapters.\n",
    "We also note here that `torch` typically\n",
    "works with 32-bit (*single precision*)\n",
    "rather than 64-bit (*double precision*) floating point numbers.\n",
    "We therefore convert our data to `np.float32` before\n",
    "forming the tensor.\n",
    "The $X$ and $Y$ tensors are then arranged into a `Dataset`\n",
    "recognized by `torch`\n",
    "using `TensorDataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dfc40df",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train.astype(np.float32))\n",
    "Y_train_t = torch.tensor(Y_train.astype(np.float32))\n",
    "hit_train = TensorDataset(X_train_t, Y_train_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9415167",
   "metadata": {},
   "source": [
    "We do the same for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f17fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_t = torch.tensor(X_test.astype(np.float32))\n",
    "Y_test_t = torch.tensor(Y_test.astype(np.float32))\n",
    "hit_test = TensorDataset(X_test_t, Y_test_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa47715",
   "metadata": {},
   "source": [
    "Finally, this dataset is passed to a `DataLoader()` which ultimately\n",
    "passes data into our network. While this may seem\n",
    "like a lot of overhead, this structure is helpful for more\n",
    "complex tasks where data may live on different machines,\n",
    "or where data must be passed to a GPU.\n",
    "We provide a helper function `SimpleDataModule()` in `ISLP` to make this task easier for\n",
    "standard usage.\n",
    "One of its arguments is `num_workers`, which indicates\n",
    "how many processes we will use\n",
    "for loading the data. For small\n",
    "data like `Hitters` this will have little effect, but\n",
    "it does provide an advantage for the `MNIST`  and `CIFAR100` examples below.\n",
    "The `torch` package will inspect the process running and determine a\n",
    "maximum number of workers. {This depends on the computing hardware and the number of cores available.} We’ve included a function\n",
    "`rec_num_workers()` to compute this so we know how many\n",
    "workers might be reasonable (here the max was 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8860952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_workers = rec_num_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc6738",
   "metadata": {},
   "source": [
    "The general training setup in `pytorch_lightning` involves\n",
    "training, validation and test data. These are each\n",
    "represented by different data loaders. During each epoch,\n",
    "we run a training step to learn the model and a validation\n",
    "step to track the error. The test data is typically\n",
    "used at the end of training to evaluate the model.\n",
    "\n",
    "In this case, as we had split only into test and training,\n",
    "we’ll use the test data as validation data with the\n",
    "argument `validation=hit_test`. The\n",
    "`validation` argument can be a float between 0 and 1, an\n",
    "integer, or a\n",
    "`Dataset`. If a float (respectively, integer), it is interpreted\n",
    "as a percentage (respectively number) of the *training* observations to be used for validation.\n",
    "If it is a `Dataset`, it is passed directly to a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "054a982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_dm = SimpleDataModule(hit_train,\n",
    "                          hit_test,\n",
    "                          batch_size=32,\n",
    "                          num_workers=min(4, max_num_workers),\n",
    "                          validation=hit_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4052d23",
   "metadata": {},
   "source": [
    "Next we must provide a `pytorch_lightning` module that controls\n",
    "the steps performed during the training process. We provide methods for our\n",
    "`SimpleModule()` that simply record the value\n",
    "of the loss function and any additional\n",
    "metrics at the end of each epoch. These operations\n",
    "are controlled by the methods `SimpleModule.[training/test/validation]_step()`, though\n",
    "we will not be modifying these in our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876d67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_module = SimpleModule.regression(hit_model,\n",
    "                           metrics={'mae':MeanAbsoluteError()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb19046",
   "metadata": {},
   "source": [
    " By using the `SimpleModule.regression()` method,  we indicate that we will use squared-error loss as in\n",
    "(10.23).\n",
    "We have also asked for mean absolute error to be tracked as well\n",
    "in the metrics that are logged.\n",
    "\n",
    "We log our results via `CSVLogger()`, which in this case stores the results in a CSV file within a directory `logs/hitters`. After the fitting is complete, this allows us to load the\n",
    "results as a `pd.DataFrame()` and visualize them below. There are\n",
    "several ways to log the results within `pytorch_lightning`, though\n",
    "we will not cover those here in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8e22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_logger = CSVLogger('logs', name='hitters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89d602",
   "metadata": {},
   "source": [
    "Finally we are ready to train our model and log the results. We\n",
    "use the `Trainer()` object from `pytorch_lightning`\n",
    "to do this work. The argument `datamodule=hit_dm` tells the trainer\n",
    "how training/validation/test logs are produced,\n",
    "while the first argument `hit_module`\n",
    "specifies the network architecture\n",
    "as well as the training/validation/test steps.\n",
    "The `callbacks` argument allows for\n",
    "several tasks to be carried out at various\n",
    "points while training a model. Here\n",
    "our `ErrorTracker()` callback will enable\n",
    "us to compute validation error while training\n",
    "and, finally, the test error.\n",
    "We now fit the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3989bae8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | HittersModel | 1.1 K \n",
      "1 | loss  | MSELoss      | 0     \n",
      "---------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f504e7292104b51b22526baa31242ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c197ae82c6864c648284fa5a29043343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71165510fe0540018dc425180a576602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4e0af005c84613977265ecf4bf04cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "hit_trainer = Trainer(deterministic=True,\n",
    "                      max_epochs=50,\n",
    "                      log_every_n_steps=5,\n",
    "                      logger=hit_logger,\n",
    "                      callbacks=[ErrorTracker()])\n",
    "hit_trainer.fit(hit_module, datamodule=hit_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24e95b",
   "metadata": {},
   "source": [
    "At each step of SGD, the algorithm randomly selects 32 training observations for\n",
    "the computation of the gradient. Recall from Section 10.7\n",
    "that an epoch amounts to the number of SGD steps required to process $n$\n",
    "observations. Since the training set has\n",
    "$n=175$, and we specified a `batch_size` of 32 in the construction of  `hit_dm`, an epoch is $175/32=5.5$ SGD steps.\n",
    "\n",
    "After having fit the model, we can evaluate performance on our test\n",
    "data using the `test()` method of our trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c550b424",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bed895bbf9432c8fca679b83d86408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss             104098.5703125\n",
      "        test_mae            229.50115966796875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 104098.5703125, 'test_mae': 229.50115966796875}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_trainer.test(hit_module, datamodule=hit_dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4f77c",
   "metadata": {},
   "source": [
    "The results of the fit have been logged into a CSV file. We can find the\n",
    "results specific to this run in the `experiment.metrics_file_path`\n",
    "attribute of our logger. Note that each time the model is fit, the logger will output\n",
    "results into a new subdirectory of our directory `logs/hitters`.\n",
    "\n",
    "We now create a plot of the MAE (mean absolute error) as a function of\n",
    "the number of epochs.\n",
    "First we retrieve the logged summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10123be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_results = pd.read_csv(hit_logger.experiment.metrics_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab41db",
   "metadata": {},
   "source": [
    "Since we will produce similar plots in later examples, we write a\n",
    "simple generic function to produce this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec25fa4e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def summary_plot(results,\n",
    "                 ax,\n",
    "                 col='loss',\n",
    "                 valid_legend='Validation',\n",
    "                 training_legend='Training',\n",
    "                 ylabel='Loss',\n",
    "                 fontsize=20):\n",
    "    for (column,\n",
    "         color,\n",
    "         label) in zip([f'train_{col}_epoch',\n",
    "                        f'valid_{col}'],\n",
    "                       ['black',\n",
    "                        'red'],\n",
    "                       [training_legend,\n",
    "                        valid_legend]):\n",
    "        results.plot(x='epoch',\n",
    "                     y=column,\n",
    "                     label=label,\n",
    "                     marker='o',\n",
    "                     color=color,\n",
    "                     ax=ax)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89edbe2d",
   "metadata": {},
   "source": [
    "We now set up our axes, and use our function to produce the MAE plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73594a6c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = subplots(1, 1, figsize=(6, 6))\n",
    "ax = summary_plot(hit_results,\n",
    "                  ax,\n",
    "                  col='mae',\n",
    "                  ylabel='MAE',\n",
    "                  valid_legend='Validation (=Test)')\n",
    "ax.set_ylim([0, 400])\n",
    "ax.set_xticks(np.linspace(0, 50, 11).astype(int));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33376f19",
   "metadata": {},
   "source": [
    "We can predict directly from the final model, and\n",
    "evaluate its performance on the test data.\n",
    "Before fitting, we call the `eval()` method\n",
    "of `hit_model`.\n",
    "This tells\n",
    "`torch` to effectively consider this model to be fitted, so that\n",
    "we can use it to predict on new data. For our model here,\n",
    "the biggest change is that the dropout layers will\n",
    "be turned off, i.e. no weights will be randomly\n",
    "dropped in predicting on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b2a88d4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(229.5012, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_model.eval() \n",
    "preds = hit_module(X_test_t)\n",
    "torch.abs(Y_test_t - preds).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30318631",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffae543",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "In setting up our data module, we had initiated\n",
    "several worker processes that will remain running.\n",
    "We delete all references to the torch objects to ensure these processes\n",
    "will be killed.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f2b7011",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "del(Hitters,\n",
    "    hit_model, hit_dm,\n",
    "    hit_logger,\n",
    "    hit_test, hit_train,\n",
    "    X, Y,\n",
    "    X_test, X_train,\n",
    "    Y_test, Y_train,\n",
    "    X_test_t, Y_test_t,\n",
    "    hit_trainer, hit_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596f7cd",
   "metadata": {},
   "source": [
    "We see that the $X$ for each batch consists of 256 images of size `1x28x28`.\n",
    "Here the `1` indicates a single channel (greyscale). For RGB images such as `CIFAR100` below,\n",
    "we will see that the `1` in the size will be replaced by `3` for the three RGB channels.\n",
    "\n",
    "Now we are ready to specify our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104c09a",
   "metadata": {},
   "source": [
    "We see that in the first layer, each `1x28x28` image is flattened, then mapped to\n",
    "256 dimensions where we apply a ReLU activation with 40% dropout.\n",
    "A second layer maps the first layer’s output down to\n",
    "128 dimensions, applying a ReLU activation with 30% dropout. Finally,\n",
    "the 128 dimensions are mapped down to 10, the number of classes in the\n",
    "`MNIST`  data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14d02c",
   "metadata": {},
   "source": [
    "We can check that the model produces output of expected size based\n",
    "on our existing batch `X_` above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be19fe2",
   "metadata": {},
   "source": [
    "Let’s take a look at the summary of the model. Instead of an `input_size` we can pass\n",
    "a tensor of correct shape. In this case, we pass through the final\n",
    "batched `X_` from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f8472",
   "metadata": {},
   "source": [
    "Having set up both  the model and the data module, fitting this model is\n",
    "now almost identical to the `Hitters` example. In contrast to our regression model, here we will use the\n",
    "`SimpleModule.classification()` method which\n",
    "uses the  cross-entropy loss function instead of mean squared error. It must be supplied with the number of\n",
    "classes in the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c08a1",
   "metadata": {},
   "source": [
    "Now we are ready to go. The final step is to supply training data, and fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e09221",
   "metadata": {},
   "source": [
    "We have suppressed the output here, which is a progress report on the\n",
    "fitting of the model, grouped by epoch. This is very useful, since on\n",
    "large datasets fitting can take time. Fitting this model took 245\n",
    "seconds on a MacBook Pro with an Apple M1 Pro chip with 10 cores and 16 GB of RAM.\n",
    "Here we specified a\n",
    "validation split of 20%, so training is actually performed on\n",
    "80% of the 60,000 observations in the training set. This is an\n",
    "alternative to actually supplying validation data, like we did for the `Hitters` data.\n",
    "SGD  uses batches\n",
    "of 256 observations in computing the gradient, and doing the\n",
    "arithmetic, we see that an epoch corresponds to 188 gradient steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d052a",
   "metadata": {},
   "source": [
    "`SimpleModule.classification()` includes\n",
    "an accuracy metric by default. Other\n",
    "classification metrics can be added from `torchmetrics`.\n",
    "We will use  our `summary_plot()` function to display \n",
    "accuracy across epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8bf50",
   "metadata": {},
   "source": [
    "Table 10.1 also reports the error rates resulting from LDA (Chapter 4) and multiclass logistic\n",
    "regression. For LDA we refer the reader to Section 4.7.3.\n",
    "Although we could use the `sklearn` function `LogisticRegression()` to fit  \n",
    "multiclass logistic regression, we are set up here to fit such a model\n",
    "with `torch`.\n",
    "We just have an input layer and an output layer, and omit the hidden layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcaef5",
   "metadata": {},
   "source": [
    "The `CIFAR100` dataset consists of 50,000 training images, each represented by a three-dimensional tensor:\n",
    "each three-color image is represented as a set of three channels, each of which consists of\n",
    "$32\\times 32$ eight-bit pixels. We standardize as we did for the\n",
    "digits, but keep the array structure. This is accomplished with the `ToTensor()` transform.\n",
    "\n",
    "Creating the data module is similar to the `MNIST`  example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca410e56",
   "metadata": {},
   "source": [
    "Before we start, we look at some of the training images; similar code produced\n",
    "Figure 10.5 on page  406. The example below also illustrates\n",
    "that `TensorDataset` objects can be indexed with integers --- we are choosing\n",
    "random images from the training data by indexing `cifar_train`. In order to display correctly,\n",
    "we must reorder the dimensions by a call to `np.transpose()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf64b3",
   "metadata": {},
   "source": [
    "Here the `imshow()` method recognizes from the shape of its argument that it is a 3-dimensional array, with the last dimension indexing the three RGB color channels.\n",
    "\n",
    "We specify a moderately-sized  CNN for\n",
    "demonstration purposes, similar in structure to Figure 10.8.\n",
    "We use several layers, each consisting of  convolution, ReLU, and max-pooling steps.\n",
    "We first define a module that defines one of these layers. As in our\n",
    "previous examples, we overwrite the `__init__()` and `forward()` methods\n",
    "of `nn.Module`. This user-defined  module can now be used in ways just like\n",
    "`nn.Linear()` or `nn.Dropout()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3e638",
   "metadata": {},
   "source": [
    "The total number of trainable parameters is 964,516.\n",
    "By studying the size of the parameters, we can see that the channels halve in both\n",
    "dimensions\n",
    "after each of these max-pooling operations. After the last of these we\n",
    "have a layer with  256 channels of dimension $2\\times 2$. These are then\n",
    "flattened to a dense layer of size 1,024;\n",
    "in other words, each of the $2\\times 2$ matrices is turned into a\n",
    "$4$-vector, and put side-by-side in one layer. This is followed by a\n",
    "dropout regularization layer,  then\n",
    "another dense layer of size 512, and finally, the\n",
    "output layer.\n",
    "\n",
    "Up to now, we have been using a default\n",
    "optimizer in `SimpleModule()`. For these data,\n",
    "experiments show that a smaller learning rate performs\n",
    "better than the default 0.01. We use a\n",
    "custom optimizer here with a learning rate of 0.001.\n",
    "Besides this, the logging and training\n",
    "follow a similar pattern to our previous examples. The optimizer\n",
    "takes an argument `params` that informs\n",
    "the optimizer which parameters are involved in SGD (stochastic gradient descent).\n",
    "\n",
    "We saw earlier that entries of a module’s parameters are tensors. In passing\n",
    "the parameters to the optimizer we are doing more than\n",
    "simply passing arrays; part of the structure of the graph\n",
    "is encoded in the tensors themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da5b69",
   "metadata": {},
   "source": [
    "This model can take 10 minutes or more to run and achieves about 42% accuracy on the test\n",
    "data. Although this is not terrible for 100-class data (a random\n",
    "classifier gets 1% accuracy), searching the web we see results around\n",
    "75%. Typically it takes a lot of architecture carpentry,\n",
    "fiddling with regularization, and time, to achieve such results.\n",
    "\n",
    "Let’s take a look at the validation and training accuracy\n",
    "across epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae730c",
   "metadata": {},
   "source": [
    "This yields approximately two- or three-fold  acceleration for each epoch.\n",
    "We have protected this code block using `try:` and `except:`\n",
    "clauses; if it works, we get the speedup, if it fails, nothing happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4c41a",
   "metadata": {},
   "source": [
    "## Using Pretrained CNN Models\n",
    "We now show how to use a CNN pretrained on the  `imagenet` database to classify natural\n",
    "images, and demonstrate how we produced Figure 10.10.\n",
    "We copied six JPEG images from a digital photo album into the\n",
    "directory `book_images`. These images are available\n",
    "from the data section of  <www.statlearning.com>, the ISLP book website. Download `book_images.zip`; when\n",
    "clicked it creates the `book_images` directory. \n",
    "\n",
    "The pretrained network we use is called `resnet50`; specification details can be found on the web.\n",
    "We will read in the images, and\n",
    "convert them into the array format expected by the `torch`\n",
    "software to match the specifications in `resnet50`. \n",
    "The conversion involves a resize, a crop and then a predefined standardization for each of the three channels.\n",
    "We now read in the images and preprocess them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a22edc",
   "metadata": {},
   "source": [
    "Inspecting the output above, we see that when setting up the\n",
    "`resnet_model`, the authors defined a `Bottleneck`, much like our\n",
    "`BuildingBlock` module.\n",
    "\n",
    "We now feed our six images through the fitted network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c89b24",
   "metadata": {},
   "source": [
    "In order to see the class labels, we must download the index file associated with `imagenet`. {This is avalable from the book website and  [s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json).}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3dc365",
   "metadata": {},
   "source": [
    "The datasets `imdb_seq_train` and `imdb_seq_test` are\n",
    "both instances of the class `TensorDataset`. The\n",
    "tensors used to construct them can be found in the `tensors` attribute, with\n",
    "the first tensor  the features `X` and the second  the outcome `Y`.\n",
    "We have taken the first row of features and stored it as `padded_sample`. In the preprocessing\n",
    "used to form these data, sequences were padded with 0s in the beginning if they were\n",
    "not long enough, hence we remove this padding by restricting to entries where\n",
    "`padded_sample > 0`. We then provide the first 12 words of the sample review.\n",
    "\n",
    "We can find these words in the `lookup` dictionary from the `ISLP.torch.imdb` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7ce47",
   "metadata": {},
   "source": [
    "We’ll again use\n",
    "a smaller learning rate for these data,\n",
    "hence we pass an `optimizer` to the\n",
    "`SimpleModule`. \n",
    "Since the reviews are classified into\n",
    "positive or negative sentiment, we use\n",
    "`SimpleModule.binary_classification()`. {Our use of\n",
    "  `binary_classification()` instead of  `classification()` is\n",
    "  due to some subtlety in how `torchmetrics.Accuracy()` works,\n",
    "as well as the data type of the targets.}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6170b",
   "metadata": {},
   "source": [
    "With `LogisticRegression()` the regularization parameter\n",
    "$C$ is specified as the inverse of $\\lambda$. There are several\n",
    "solvers for logistic regression; here we use `liblinear` which\n",
    "works well with the sparse input format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061eec6",
   "metadata": {},
   "source": [
    "Notice the use of `%%capture`, which suppresses the displaying of the partially completed figure. This is useful\n",
    "when making a complex figure, since the steps can be spread across two or more cells.\n",
    "We now add a plot of the lasso accuracy, and display the composed figure by simply entering its name at the end of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1161e9",
   "metadata": {},
   "source": [
    "The first layer of the RNN is an embedding layer of size 32, which will be\n",
    "learned during  training. This layer one-hot encodes  each document\n",
    "as a matrix of dimension $500 \\times 10,003$, and then maps these\n",
    "$10,003$ dimensions down to $32$. {The extra 3 dimensions\n",
    "correspond to commonly occurring non-word entries in the reviews.}\n",
    " Since each word is represented by an\n",
    "integer, this is effectively achieved by the creation of an embedding\n",
    "matrix of size $10,003\\times 32$; each of the 500 integers in the\n",
    "document are then mapped to the appropriate 32 real numbers by\n",
    "indexing the appropriate rows of this matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098afce",
   "metadata": {},
   "source": [
    "The second  layer is an LSTM with 32 units, and the output\n",
    "layer is a single logit for the binary classification task.\n",
    "In the last line of the `forward()` method below,\n",
    "we take the last 32-dimensional output of the LSTM and map it to our response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146e793",
   "metadata": {},
   "source": [
    "Finally, we extract the response, training indicator, and drop the current day’s `DJ_return` and\n",
    "`log_volatility` to predict only from previous day’s data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd08c9",
   "metadata": {},
   "source": [
    "We refit this model, including the factor variable `day_of_week`.\n",
    "For a categorical series in `pandas`, we can form the indicators\n",
    "using the `get_dummies()`  method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120352d5",
   "metadata": {},
   "source": [
    "To fit the RNN, we must reshape the data, as it will expect 5 lagged\n",
    "versions of each feature as indicated by the  `input_shape` argument\n",
    "to the layer `nn.RNN()`  below. We first\n",
    "ensure the columns of  our data frame are such that a reshaped\n",
    "matrix will have the variables correctly lagged. We use the\n",
    "`reindex()`  method to do this.\n",
    "\n",
    "For an input shape `(5,3)`, each row represents a lagged version of the three variables.\n",
    "The `nn.RNN()` layer also expects the first row of each\n",
    "observation to be earliest in time, so we must reverse the current order.  Hence we loop over\n",
    "`range(5,0,-1)` below, which is\n",
    "an example of using a  `slice()`  to index\n",
    "iterable objects. The general notation is `start:end:step`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965be876",
   "metadata": {},
   "source": [
    "We  fit the model in a similar fashion to previous networks. We\n",
    "supply the `fit` function with test data as validation data, so that when\n",
    "we monitor its progress and plot the history function we can see the\n",
    "progress on the test data. Of course we should not use this as a basis for\n",
    "early stopping, since then the test performance would be biased.\n",
    "\n",
    "We form the training dataset similar to\n",
    "our `Hitters` example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a6503",
   "metadata": {},
   "source": [
    "We could also fit a model without the `nn.RNN()` layer by just\n",
    "using a `nn.Flatten()` layer instead. This would be a nonlinear AR model. If in addition we excluded the \n",
    "hidden layer, this would be equivalent to our earlier linear AR model.  \n",
    "\n",
    "Instead we will fit a nonlinear AR model using the feature set `X_day` that includes the `day_of_week` indicators.\n",
    "To do so, we\n",
    "must first create our test and training datasets and a corresponding\n",
    "data module. This may seem a little burdensome, but is part of the\n",
    "general pipeline for `torch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2caf04",
   "metadata": {},
   "source": [
    "We continue with the usual training steps, fit the model,\n",
    "and evaluate the test error. We see the test $R^2$ is a slight improvement over the linear AR model that also includes `day_of_week`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
